{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 06:49:54.975602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 06:49:55.315072: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-28 06:49:55.315093: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-28 06:49:55.358456: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-28 06:49:56.526207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-28 06:49:56.526304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-28 06:49:56.526312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Image_Folder</th>\n",
       "      <th>geometry</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image_Folder_long_lat</th>\n",
       "      <th>img_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43.948271</td>\n",
       "      <td>-93.649496</td>\n",
       "      <td>CAFOs</td>\n",
       "      <td>MinnesotaPollutionControlAgency</td>\n",
       "      <td>train_images/43.94827109_-93.6494963</td>\n",
       "      <td>POLYGON ((-93.64626236497716 43.95060750304138...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.94827109_-93.6494963</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.004434</td>\n",
       "      <td>-78.208900</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aeroplanes</td>\n",
       "      <td>train_images/43.00443446102501_-78.20890003579709</td>\n",
       "      <td>POLYGON ((-78.20566610077425 43.00680791855935...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.00443446102501_-78.20890003579709</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Latitude  Longitude      Type  \\\n",
       "0           0  43.948271 -93.649496     CAFOs   \n",
       "1           1  43.004434 -78.208900  Negative   \n",
       "\n",
       "                            Source  \\\n",
       "0  MinnesotaPollutionControlAgency   \n",
       "1                       Aeroplanes   \n",
       "\n",
       "                                        Image_Folder  \\\n",
       "0               train_images/43.94827109_-93.6494963   \n",
       "1  train_images/43.00443446102501_-78.20890003579709   \n",
       "\n",
       "                                            geometry dataset  \\\n",
       "0  POLYGON ((-93.64626236497716 43.95060750304138...   train   \n",
       "1  POLYGON ((-78.20566610077425 43.00680791855935...   train   \n",
       "\n",
       "                  Image_Folder_long_lat  \\\n",
       "0               43.94827109_-93.6494963   \n",
       "1  43.00443446102501_-78.20890003579709   \n",
       "\n",
       "                                             img_dir  \n",
       "0  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...  \n",
       "1  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/home/csantiago3/code/carlajord/week_5/baseline/methane_224_data' #os.getcwd()\n",
    "data = pd.read_csv('methane_224_data/smallsize224_all.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_path'] = data['img_dir'].apply(lambda x: x.replace(\"F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\\", \"\") \\\n",
    "         .replace(\"\\\\\\\\\", \"/\").replace(\"\\\\\", \"/\"))\n",
    "os.path.exists(os.path.join(root, data['new_path'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86599, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unknowns\n",
    "data = data.dropna()\n",
    "\n",
    "# leave just unique categories\n",
    "data = data[(data.Type == 'Negative') | (data.Type == 'CAFOs') | (data.Type == 'WWTreatment')\n",
    "           | (data.Type == 'Landfills') | (data.Type == 'RefineriesAndTerminals')\n",
    "           | (data.Type == 'ProcessingPlants') | (data.Type == 'Mines')]\n",
    "\n",
    "# shuffle in-place\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86188, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['dataset'] == \"train\"]\n",
    "df_test = data.loc[data['dataset'] == \"val\"]\n",
    "\n",
    "# reset indices\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84693, 11), (505, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "BASELINE_SPLIT = 0.2 # Run baseline with 10% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data, _ = np.split(df_train, [int(BASELINE_SPLIT*len(df_train))])\n",
    "#base_data = df_train.sample(n=BASELINE_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0.40375237622944044,\n",
       " 'CAFOs': 0.2944044962393586,\n",
       " 'WWTreatment': 0.16879789356853578,\n",
       " 'Landfills': 0.046225780170734296,\n",
       " 'RefineriesAndTerminals': 0.04506865974755883,\n",
       " 'ProcessingPlants': 0.02160745280011335,\n",
       " 'Mines': 0.020143341244258674}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df_train.Type.value_counts()/len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0.4009918526390365,\n",
       " 'CAFOs': 0.29596174282678,\n",
       " 'WWTreatment': 0.16961860904475146,\n",
       " 'Landfills': 0.04669972842130122,\n",
       " 'RefineriesAndTerminals': 0.04622741764080765,\n",
       " 'ProcessingPlants': 0.020545518951470068,\n",
       " 'Mines': 0.019955130475853112}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_predictions = dict(base_data.Type.value_counts()/len(base_data))\n",
    "proba_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_BATCH = base_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFrameIterator(image.DataFrameIterator):\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_, y_ = super().__getitem__(idx)\n",
    "        y_ = np.delete(y_, self.class_indices['Negative'], axis=1)\n",
    "        return X_, y_\n",
    "    \n",
    "    def next(self):\n",
    "        X_, y_ = super().next()\n",
    "        y_ = np.delete(y_, self.class_indices['Negative'], axis=1)\n",
    "        return X_, y_\n",
    "    \n",
    "class MyImageDataGenerator(image.ImageDataGenerator):\n",
    "    \n",
    "    def flow_from_dataframe(self, df, directory, *args, **kwargs):\n",
    "        return MyDataFrameIterator(df, directory, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 07:17:03.075942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-28 07:17:03.075992: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-28 07:17:03.076012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SLB-980BVT2): /proc/driver/nvidia/version does not exist\n",
      "2023-05-28 07:17:03.076216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate metrics\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "pr_auc = tf.keras.metrics.AUC(name='pr_auc', curve='PR')\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "metrics_fun = {'Precision': precision,\n",
    "               'Recall': recall,\n",
    "               'AUC': auc,\n",
    "               'PR-AUC': pr_auc,\n",
    "               'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, metrics_fun, cat_idx):\n",
    "    \n",
    "    \"\"\"Computes metrics and stores results in list\"\"\"\n",
    "\n",
    "    metrics_results = []\n",
    "    for func in metrics_fun:\n",
    "        func.reset_states()\n",
    "        metrics_results.append(func(y_true[:][:,cat_idx].reshape(BASELINE_BATCH,1),\n",
    "                                    y_pred[:][:,cat_idx].reshape(BASELINE_BATCH,1)).numpy())\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16938 non-validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get y_true\n",
    "datagen = MyImageDataGenerator(rescale=1./255)\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "                    base_data,\n",
    "                    root,\n",
    "                    x_col=\"new_path\",\n",
    "                    y_col=\"Type\",\n",
    "                    color_mode='rgb',\n",
    "                    seed = SEED,\n",
    "                    class_mode=\"categorical\",\n",
    "                    validate_filenames=False,\n",
    "                    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "                    batch_size=BASELINE_BATCH)\n",
    "_, y_true = train_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAFOs': 0.29596174282678,\n",
       " 'Landfills': 0.04669972842130122,\n",
       " 'Mines': 0.019955130475853112,\n",
       " 'ProcessingPlants': 0.020545518951470068,\n",
       " 'RefineriesAndTerminals': 0.04622741764080765,\n",
       " 'WWTreatment': 0.16961860904475146}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names = list(train_gen.class_indices.keys())\n",
    "cat_names.remove('Negative')\n",
    "probs = {}\n",
    "for cat in cat_names:\n",
    "    probs[cat] = proba_predictions[cat]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Y pred\n",
    "def compute_baseline_metric(y_true, prob, metrics_fun):\n",
    "\n",
    "    \"\"\" Generates y prediction for given category probability \"\"\"\n",
    "    \n",
    "    # instantiate y_pred\n",
    "    y_pred = np.zeros_like(y_true)\n",
    "    # get indices for values to be assigned True\n",
    "    n_samples = y_pred.shape[0]\n",
    "    indices = np.random.choice(n_samples, np.round(n_samples*prob).astype(np.uint32), replace=False)\n",
    "    y_pred[indices] = 1\n",
    "\n",
    "    # compute metrics\n",
    "    metrics_results = []\n",
    "    for func in metrics_fun:\n",
    "        func.reset_states()\n",
    "        metrics_results.append(func(y_true.reshape(BASELINE_BATCH, 1),\n",
    "                                    y_pred.reshape(BASELINE_BATCH,1)).numpy())\n",
    "    return metrics_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_metrics = {}\n",
    "for cat_idx, cat in enumerate(list(probs.keys())):\n",
    "    \n",
    "    # Instantiate dictionary that stores metrics per category\n",
    "    cat_metrics[cat] = {}\n",
    "    for m in metrics_fun.keys():\n",
    "        cat_metrics[cat][m] = []\n",
    "\n",
    "    # Take 5 samples of y_prediction for each category and compute average metrics\n",
    "    cnt = 0\n",
    "    while cnt < 2:\n",
    "\n",
    "        m_results = compute_baseline_metric(y_true[:, cat_idx], probs[cat], metrics_fun.values())\n",
    "        \n",
    "        # Store all calculated metrics\n",
    "        for m_idx, m in enumerate(metrics_fun.keys()):\n",
    "            cat_metrics[cat][m].append(m_results[m_idx])\n",
    "        cnt+=1\n",
    "        \n",
    "    for m in metrics_fun.keys():\n",
    "        cat_metrics[cat][m] = np.mean(np.array(cat_metrics[cat][m]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAFOs</th>\n",
       "      <th>Landfills</th>\n",
       "      <th>Mines</th>\n",
       "      <th>ProcessingPlants</th>\n",
       "      <th>RefineriesAndTerminals</th>\n",
       "      <th>WWTreatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.295332</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.295332</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.499553</td>\n",
       "      <td>0.499046</td>\n",
       "      <td>0.495857</td>\n",
       "      <td>0.497580</td>\n",
       "      <td>0.496856</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR-AUC</th>\n",
       "      <td>0.295699</td>\n",
       "      <td>0.046447</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>0.045375</td>\n",
       "      <td>0.167833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.582891</td>\n",
       "      <td>0.910792</td>\n",
       "      <td>0.960562</td>\n",
       "      <td>0.959558</td>\n",
       "      <td>0.911265</td>\n",
       "      <td>0.716614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CAFOs  Landfills     Mines  ProcessingPlants  \\\n",
       "Precision  0.295332   0.044880  0.011834          0.015805   \n",
       "Recall     0.295332   0.044880  0.011834          0.015805   \n",
       "AUC        0.499553   0.499046  0.495857          0.497580   \n",
       "PR-AUC     0.295699   0.046447  0.019378          0.020182   \n",
       "Accuracy   0.582891   0.910792  0.960562          0.959558   \n",
       "\n",
       "           RefineriesAndTerminals  WWTreatment  \n",
       "Precision                0.040230     0.164636  \n",
       "Recall                   0.040230     0.164636  \n",
       "AUC                      0.496856     0.497000  \n",
       "PR-AUC                   0.045375     0.167833  \n",
       "Accuracy                 0.911265     0.716614  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cat_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
