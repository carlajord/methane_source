{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE NOTEBOOK "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following metrics will be used for the model:\n",
    "\n",
    "`auc`= Approximates the AUC (Area under the curve) of the ROC or PR curves. (ROC / PR)\n",
    "\n",
    "`Precision` \n",
    "\n",
    "`Recall `\n",
    "\n",
    "`F1`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general `Baseline` for data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, folium, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imageio.v3 as iio\n",
    "import geopandas as gpd\n",
    "from IPython.display import Image, display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, backend, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.applications import EfficientNetB0, DenseNet121\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= gpd.read_file('labels.geojson')\n",
    "labels_unique = labels[(labels.Type == 'Negative') | (labels.Type == 'CAFOs') | (labels.Type == 'WWTreatment')\n",
    "           | (labels.Type == 'Landfills') | (labels.Type == 'RefineriesAndTerminals')\n",
    "           | (labels.Type == 'ProcessingPlants') | (labels.Type == 'Mines')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CAFOs', 'Landfills', 'Mines', 'Negative', 'ProcessingPlants',\n",
       "       'RefineriesAndTerminals', 'WWTreatment'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labels_unique.Type.values.reshape(labels_unique.Type.values.shape[0], 1))\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test= train_test_split(y, train_size=0.1, stratify=y)\n",
    "def invert_ecoding(encoded_labels, categories):\n",
    "    categories = ['[unk]']+categories\n",
    "    return np.take(categories, np.argwhere(encoded_labels == 1.0)[:,1])\n",
    "y_tra_orig = np.argwhere(y_train == 1.0)[:,1]\n",
    "y_test_orig = np.argwhere(y_test == 1.0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 3, ..., 0, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# same probability for all the instances\n",
    "constant_probability = np.full_like(y_test, 1/7)\n",
    "\n",
    "y_pred_baseline = np.argmax(constant_probability, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_baseline)\n",
    "precision = precision_score(np.argmax(y_test, axis=1), y_pred_baseline, average='weighted')\n",
    "recall = recall_score(np.argmax(y_test, axis=1), y_pred_baseline, average='weighted')\n",
    "f1 = f1_score(np.argmax(y_test, axis=1), y_pred_baseline, average='weighted')\n",
    "auc = roc_auc_score(y_test, constant_probability, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC'],\n",
    "    'value': [accuracy, precision, recall, f1, auc]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.289995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.084097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.289995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.130384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     value\n",
       "0   Accuracy  0.289995\n",
       "1  Precision  0.084097\n",
       "2     Recall  0.289995\n",
       "3   F1-score  0.130384\n",
       "4        AUC  0.500000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Baseline` CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "##labels_unique.Image_Folder=labels_unique.Image_Folder+\"/naip.png\"\n",
    "##separate the datasets in train and test\n",
    "train = int(labels_unique.shape[0] * 0.8)\n",
    "test = int(labels_unique.shape[0] * 0.2)\n",
    "labels_unique_train = labels_unique.iloc[:train, :]\n",
    "labels_unique_test = labels_unique.iloc[train:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##input data \n",
    "image_size = (720, 720)\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "##get images from path on train and test \n",
    "\n",
    "from keras.preprocessing import image\n",
    "dir_path=r\"/root/code/dvictoria2/methane_source/\"\n",
    "train_datagen=image.ImageDataGenerator(rescale=1./255, validation_split = validation_split)\n",
    "test_datagen =image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9040 validated image filenames belonging to 7 classes.\n",
      "Found 2260 validated image filenames belonging to 7 classes.\n",
      "Found 2826 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "##create generators for train_validation and test\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels_unique_train, directory=dir_path, \n",
    "    x_col=\"Image_Folder\", y_col=\"Type\", seed = 42,\n",
    "    class_mode=\"categorical\", target_size=(720,720), batch_size=batch_size , subset = \"training\", color_mode='rgb')\n",
    "validation_generator = train_datagen.flow_from_dataframe(dataframe=labels_unique_train, directory=dir_path, \n",
    "    x_col=\"Image_Folder\", y_col=\"Type\", seed = 42,\n",
    "    class_mode=\"categorical\", target_size=(720,720), batch_size=batch_size , subset = \"validation\", color_mode='rgb')\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=labels_unique_test, directory=dir_path, \n",
    "    x_col=\"Image_Folder\", y_col=\"Type\", seed = 42,\n",
    "    class_mode=\"categorical\", target_size=(720,720), batch_size=batch_size , color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create build_model funtion\n",
    "def build_model():\n",
    "    inputs = layers.Input(shape=(720, 720, 3))\n",
    "    \n",
    "    cnn = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    cnn2 = layers.MaxPooling2D((2, 2))(cnn)\n",
    "    cnn3 = layers.Conv2D(64, (3, 3), activation='relu')(cnn2)\n",
    "    cnn4 = layers.MaxPooling2D((2, 2))(cnn3)\n",
    "    \n",
    "    flatten = layers.Flatten()(cnn4)\n",
    "    dense1 = layers.Dense(32, activation='relu')(flatten)\n",
    "    out = layers.Dense(7, activation='softmax')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.AUC(name='pr_auc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        'f1_score', \n",
    "        'accuracy'\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [callbacks.EarlyStopping(patience=5), callbacks.ReduceLROnPlateau(patience=3),callbacks.ModelCheckpoint('methane_V1.hdf5', monitor='loss',verbose=1, save_best_only=True)]\n",
    "epochs = 10\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history =model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10, callbacks = cb)\n",
    "\n",
    "# evaluate the test set\n",
    "test_loss, test_metrics = model.evaluate(test_generator, steps=STEP_SIZE_TEST)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
