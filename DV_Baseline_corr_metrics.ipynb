{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9883560c",
   "metadata": {},
   "source": [
    "# BASELINE NOTEBOOK "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5020c01",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "121f2d99",
   "metadata": {},
   "source": [
    "the following metrics will be used for the model:\n",
    "\n",
    "`auc`= Approximates the AUC (Area under the curve) of the ROC or PR curves. (ROC / PR)\n",
    "\n",
    "`Precision` \n",
    "\n",
    "`Recall `\n",
    "\n",
    "`F1`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "839f83bc",
   "metadata": {},
   "source": [
    "## general `Baseline` for data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69cd5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import imageio\n",
    "import geopandas as gpd\n",
    "from IPython.display import Image, display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, backend, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, recall_score, roc_auc_score, f1_score, precision_score\n",
    "import pickle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b5f8ff5",
   "metadata": {},
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a235b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./methane_224_data/smallsize224_all.csv\")\n",
    "df=df.dropna()\n",
    "root = 'methane_224_data/smallsize224/'\n",
    "abc = 'F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\smallsize224\\\\\\\\train_images_1\\\\train_images_1\\\\43.94827109_-93.6494963\\\\naip.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326f00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82544f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Image_Folder</th>\n",
       "      <th>geometry</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image_Folder_long_lat</th>\n",
       "      <th>img_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43.948271</td>\n",
       "      <td>-93.649496</td>\n",
       "      <td>CAFOs</td>\n",
       "      <td>MinnesotaPollutionControlAgency</td>\n",
       "      <td>train_images/43.94827109_-93.6494963</td>\n",
       "      <td>POLYGON ((-93.64626236497716 43.95060750304138...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.94827109_-93.6494963</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.004434</td>\n",
       "      <td>-78.208900</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aeroplanes</td>\n",
       "      <td>train_images/43.00443446102501_-78.20890003579709</td>\n",
       "      <td>POLYGON ((-78.20566610077425 43.00680791855935...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.00443446102501_-78.20890003579709</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Latitude  Longitude      Type  \\\n",
       "0           0  43.948271 -93.649496     CAFOs   \n",
       "1           1  43.004434 -78.208900  Negative   \n",
       "\n",
       "                            Source  \\\n",
       "0  MinnesotaPollutionControlAgency   \n",
       "1                       Aeroplanes   \n",
       "\n",
       "                                        Image_Folder  \\\n",
       "0               train_images/43.94827109_-93.6494963   \n",
       "1  train_images/43.00443446102501_-78.20890003579709   \n",
       "\n",
       "                                            geometry dataset  \\\n",
       "0  POLYGON ((-93.64626236497716 43.95060750304138...   train   \n",
       "1  POLYGON ((-78.20566610077425 43.00680791855935...   train   \n",
       "\n",
       "                  Image_Folder_long_lat  \\\n",
       "0               43.94827109_-93.6494963   \n",
       "1  43.00443446102501_-78.20890003579709   \n",
       "\n",
       "                                             img_dir  \n",
       "0  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...  \n",
       "1  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b37f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type = df.Type.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5484b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_path'] = df.img_dir.apply(lambda x: x.replace('F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\smallsize224\\\\\\\\', root)\\\n",
    "    .replace('F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\smallsize224_val\\\\\\\\', root)\\\n",
    "    .replace('F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\smallsize224_test\\\\\\\\', root)\\\n",
    "    .replace(\"\\\\\\\\\", \"/\"))\n",
    "#    .replace('F:\\\\\\\\CNOOC_testing\\\\\\\\Methane_dataset\\\\\\\\METHANE_PROJECT\\\\\\\\smallsize224_val\\\\\\\\val_images\\\\\\\\val_images\\\\', root).replace(\"\\\\\", \"/\").replace(\"//\",\"/\"))\n",
    "df['new_path'] = df.new_path.apply(lambda x: x.replace(\"\\\\\",\"/\"))\n",
    "df.new_path.to_list()[-1],df.img_dir.to_list()[-1]\n",
    "df.Type = df.Type.astype(str)\n",
    "df_train=df.loc[df['dataset'] == \"train\"]\n",
    "df_test=df.loc[df['dataset'] == \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea63afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train.Type == 'Negative') | (df_train.Type == 'CAFOs') | (df_train.Type == 'WWTreatment')\n",
    "           | (df_train.Type == 'Landfills') | (df_train.Type == 'RefineriesAndTerminals')\n",
    "           | (df_train.Type == 'ProcessingPlants') | (df_train.Type == 'Mines')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3442f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[(df_test.Type == 'Negative') | (df_test.Type == 'CAFOs') | (df_test.Type == 'WWTreatment')\n",
    "           | (df_test.Type == 'Landfills') | (df_test.Type == 'RefineriesAndTerminals')\n",
    "           | (df_test.Type == 'ProcessingPlants') | (df_test.Type == 'Mines')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0b4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataframes in place\n",
    "#df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "#df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2861ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Image_Folder</th>\n",
       "      <th>geometry</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image_Folder_long_lat</th>\n",
       "      <th>img_dir</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43.948271</td>\n",
       "      <td>-93.649496</td>\n",
       "      <td>CAFOs</td>\n",
       "      <td>MinnesotaPollutionControlAgency</td>\n",
       "      <td>train_images/43.94827109_-93.6494963</td>\n",
       "      <td>POLYGON ((-93.64626236497716 43.95060750304138...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.94827109_-93.6494963</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "      <td>methane_224_data/smallsize224/train_images_1/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.004434</td>\n",
       "      <td>-78.208900</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Aeroplanes</td>\n",
       "      <td>train_images/43.00443446102501_-78.20890003579709</td>\n",
       "      <td>POLYGON ((-78.20566610077425 43.00680791855935...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.00443446102501_-78.20890003579709</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "      <td>methane_224_data/smallsize224/train_images_3/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38.616000</td>\n",
       "      <td>-77.270000</td>\n",
       "      <td>WWTreatment</td>\n",
       "      <td>HydroWASTE</td>\n",
       "      <td>train_images/38.616_-77.27</td>\n",
       "      <td>POLYGON ((-77.26676606497716 38.61853717422367...</td>\n",
       "      <td>train</td>\n",
       "      <td>38.616_-77.27</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "      <td>methane_224_data/smallsize224/train_images_2/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>44.672960</td>\n",
       "      <td>-95.153570</td>\n",
       "      <td>CAFOs</td>\n",
       "      <td>MinnesotaPollutionControlAgency</td>\n",
       "      <td>train_images/44.67296_-95.15357</td>\n",
       "      <td>POLYGON ((-95.15033606497715 44.67526754438732...</td>\n",
       "      <td>train</td>\n",
       "      <td>44.67296_-95.15357</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "      <td>methane_224_data/smallsize224/train_images_2/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43.923000</td>\n",
       "      <td>-111.611000</td>\n",
       "      <td>WWTreatment</td>\n",
       "      <td>HydroWASTE</td>\n",
       "      <td>train_images/43.923_-111.611</td>\n",
       "      <td>POLYGON ((-111.60776606497717 43.9253374131065...</td>\n",
       "      <td>train</td>\n",
       "      <td>43.923_-111.611</td>\n",
       "      <td>F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...</td>\n",
       "      <td>methane_224_data/smallsize224/train_images_1/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Latitude   Longitude         Type  \\\n",
       "0           0  43.948271  -93.649496        CAFOs   \n",
       "1           1  43.004434  -78.208900     Negative   \n",
       "2           2  38.616000  -77.270000  WWTreatment   \n",
       "3           3  44.672960  -95.153570        CAFOs   \n",
       "4           4  43.923000 -111.611000  WWTreatment   \n",
       "\n",
       "                            Source  \\\n",
       "0  MinnesotaPollutionControlAgency   \n",
       "1                       Aeroplanes   \n",
       "2                       HydroWASTE   \n",
       "3  MinnesotaPollutionControlAgency   \n",
       "4                       HydroWASTE   \n",
       "\n",
       "                                        Image_Folder  \\\n",
       "0               train_images/43.94827109_-93.6494963   \n",
       "1  train_images/43.00443446102501_-78.20890003579709   \n",
       "2                         train_images/38.616_-77.27   \n",
       "3                    train_images/44.67296_-95.15357   \n",
       "4                       train_images/43.923_-111.611   \n",
       "\n",
       "                                            geometry dataset  \\\n",
       "0  POLYGON ((-93.64626236497716 43.95060750304138...   train   \n",
       "1  POLYGON ((-78.20566610077425 43.00680791855935...   train   \n",
       "2  POLYGON ((-77.26676606497716 38.61853717422367...   train   \n",
       "3  POLYGON ((-95.15033606497715 44.67526754438732...   train   \n",
       "4  POLYGON ((-111.60776606497717 43.9253374131065...   train   \n",
       "\n",
       "                  Image_Folder_long_lat  \\\n",
       "0               43.94827109_-93.6494963   \n",
       "1  43.00443446102501_-78.20890003579709   \n",
       "2                         38.616_-77.27   \n",
       "3                    44.67296_-95.15357   \n",
       "4                       43.923_-111.611   \n",
       "\n",
       "                                             img_dir  \\\n",
       "0  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...   \n",
       "1  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...   \n",
       "2  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...   \n",
       "3  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...   \n",
       "4  F:\\\\CNOOC_testing\\\\Methane_dataset\\\\METHANE_PR...   \n",
       "\n",
       "                                            new_path  \n",
       "0  methane_224_data/smallsize224/train_images_1/t...  \n",
       "1  methane_224_data/smallsize224/train_images_3/t...  \n",
       "2  methane_224_data/smallsize224/train_images_2/t...  \n",
       "3  methane_224_data/smallsize224/train_images_2/t...  \n",
       "4  methane_224_data/smallsize224/train_images_1/t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfaabda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53155860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative                  34195\n",
       "CAFOs                     24934\n",
       "WWTreatment               14296\n",
       "Landfills                  3915\n",
       "RefineriesAndTerminals     3817\n",
       "ProcessingPlants           1830\n",
       "Mines                      1706\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eda061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sampling_k_elements(group, k=1600):\n",
    "#    if len(group) < k:\n",
    "#        return group\n",
    "#    return group.sample(k)\n",
    "#balanced = df_train.groupby('Type').apply(sampling_k_elements).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "364a375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "CATEGORIES = 6\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82b302ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, train_data = np.split(df_train, [int(VAL_SPLIT*len(df_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf175af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFrameIterator(image.DataFrameIterator):\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_, y_ = super().__getitem__(idx)\n",
    "        y_ = np.delete(y_, self.class_indices['Negative'], axis=1)\n",
    "        return X_, y_\n",
    "    \n",
    "    def next(self):\n",
    "        X_, y_ = super().next()\n",
    "        y_ = np.delete(y_, self.class_indices['Negative'], axis=1)\n",
    "        return X_, y_\n",
    "    \n",
    "class MyImageDataGenerator(image.ImageDataGenerator):\n",
    "    \n",
    "    def flow_from_dataframe(self, df, directory, *args, **kwargs):\n",
    "        return MyDataFrameIterator(df, directory, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e0f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=MyImageDataGenerator(rescale=1./255,\n",
    "                             #validation_split = VAL_SPLIT, # do not use this one :)\n",
    "                             #rotation_range=20,\n",
    "                             #width_shift_range=0.2,\n",
    "                             #height_shift_range=0.2,\n",
    "                             #horizontal_flip=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6c76e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67755 non-validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    \"\",\n",
    "    x_col=\"new_path\",\n",
    "    y_col=\"Type\",\n",
    "    color_mode='rgb',\n",
    "    seed = SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    validate_filenames=False,\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "    batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "661cb042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16938 non-validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    \"\",\n",
    "    x_col=\"new_path\",\n",
    "    y_col=\"Type\",\n",
    "    color_mode='rgb',\n",
    "    seed = SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "    validate_filenames=False,\n",
    "    batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3af9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 990 non-validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_BATCH_SIZE = 500\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    \"\",\n",
    "    x_col = \"new_path\",\n",
    "    y_col = \"Type\",\n",
    "    color_mode = 'rgb',\n",
    "    seed = SEED,\n",
    "    class_mode = \"categorical\",\n",
    "    validate_filenames=False,\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "    batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07605cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_gen.class_indices == test_gen.class_indices\n",
    "assert train_gen.class_indices == val_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd788d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n//train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n//val_gen.batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e01cc7b",
   "metadata": {},
   "source": [
    "## `Baseline` probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "199046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test= train_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "498e4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = pd.Series(train_gen.classes).value_counts().sort_index()\n",
    "class_labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "class_counts_df = pd.DataFrame({\n",
    "    'class_label': class_labels,\n",
    "    'count': class_counts.values\n",
    "})\n",
    "class_probabilities = class_counts_df['count'] / class_counts_df['count'].sum()\n",
    "constant_probability = np.tile(class_probabilities.values, (len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d65f610e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_labels</th>\n",
       "      <th>class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAFOs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Landfills</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mines</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ProcessingPlants</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RefineriesAndTerminals</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WWTreatment</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class_labels  class_index\n",
       "0                   CAFOs            0\n",
       "1               Landfills            1\n",
       "2                   Mines            2\n",
       "3                Negative            3\n",
       "4        ProcessingPlants            4\n",
       "5  RefineriesAndTerminals            5\n",
       "6             WWTreatment            6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = list(train_gen.class_indices.keys())\n",
    "data = {'class_labels': class_labels, 'class_index': list(train_gen.class_indices.values())}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cc39300",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_probability=np.delete(constant_probability, 3, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02572535",
   "metadata": {},
   "source": [
    "### baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f2c6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred_proba= constant_probability\n",
    "cat_names= class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "271252ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ],\n",
       "       [0.29287875, 0.04683049, 0.02023467, 0.02205003, 0.04507416,\n",
       "        0.1688879 ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfc0094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate metrics\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "pr_auc = tf.keras.metrics.AUC(name='pr_auc', curve='PR')\n",
    "accuracy = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76018cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize predictions\n",
    "y_pred = np.argmax(y_pred_proba).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46eecacb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 64 into shape (512,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb Celda 38\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(cat_names):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m m_dict, m_fun \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dicts, funcs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         calc_metric(y_test, y_pred, m_dict, m_fun, idx, name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     overall_cat[name] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean([d[name] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dicts])\n",
      "\u001b[1;32m/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb Celda 38\u001b[0m in \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_metric\u001b[39m(y_test, y_pred, m_dict, m_fun, idx, name):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     m_dict[name] \u001b[39m=\u001b[39m m_fun(y_test[:][:,idx]\u001b[39m.\u001b[39;49mreshape(TEST_BATCH_SIZE,\u001b[39m1\u001b[39;49m), y_pred[:][:,idx]\u001b[39m.\u001b[39mreshape(TEST_BATCH_SIZE,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 64 into shape (512,1)"
     ]
    }
   ],
   "source": [
    "prec_cat = {}\n",
    "recall_cat = {}\n",
    "auc_cat = {}\n",
    "pr_auc_cat = {}\n",
    "accuracy_cat = {}\n",
    "overall_cat = {}\n",
    "\n",
    "def calc_metric(y_test, y_pred, m_dict, m_fun, idx, name):\n",
    "    m_dict[name] = m_fun(y_test[:][:,idx].reshape(TEST_BATCH_SIZE,1), y_pred[:][:,idx].reshape(TEST_BATCH_SIZE,1)).numpy()\n",
    "\n",
    "dicts = [prec_cat, recall_cat, auc_cat, pr_auc_cat, accuracy_cat]\n",
    "funcs = [precision, recall, auc, pr_auc, accuracy]\n",
    "\n",
    "for idx, name in enumerate(cat_names):\n",
    "    for m_dict, m_fun in zip(dicts, funcs):\n",
    "        calc_metric(y_test, y_pred, m_dict, m_fun, idx, name)\n",
    "    overall_cat[name] = np.mean([d[name] for d in dicts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c784799",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Category': cat_names,\n",
    "    'Precision': list(prec_cat.values()),\n",
    "    'Recall': list(recall_cat.values()),\n",
    "    'AUC': list(auc_cat.values()),\n",
    "    'PR AUC': list(pr_auc_cat.values()),\n",
    "    'Accuracy': list(accuracy_cat.values()),\n",
    "    'Overall': list(overall_cat.values())\n",
    "})\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23650824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy precision recall   f1  auc\n",
      "CAFOs                   0.828125       0.0    0.0  0.0  0.5\n",
      "Landfills                   0.75       0.0    0.0  0.0  0.5\n",
      "Mines                   0.984375       0.0    0.0  0.0  0.5\n",
      "Negative                0.984375       0.0    0.0  0.0  0.5\n",
      "ProcessingPlants             1.0       0.0    0.0  0.0  NaN\n",
      "RefineriesAndTerminals       1.0       0.0    0.0  0.0  NaN\n",
      "WWTreatment             0.828125       0.0    0.0  0.0  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/root/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" metrics_df = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1', 'auc'], index=class_labels)\n",
    "\n",
    "for i, class_name in enumerate(class_labels):\n",
    "    y_true_class = y_true[:, i-1]\n",
    "    y_pred_class = y_pred[:, i-1]\n",
    "    y_pred_binary = (y_pred_class > 0.5)\n",
    "\n",
    "    accuracy = accuracy_score(y_true_class, y_pred_binary)\n",
    "    precision = precision_score(y_true_class, y_pred_binary)\n",
    "    recall = recall_score(y_true_class, y_pred_binary)\n",
    "    f1 = f1_score(y_true_class, y_pred_binary)\n",
    "\n",
    "    if len(np.unique(y_true_class)) > 1:  # AUC is only defined when there is at least one positive and one negative instance.\n",
    "        auc = roc_auc_score(y_true_class, y_pred_class)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "    metrics_df.loc[class_name] = [accuracy, precision, recall, f1, auc]\n",
    "\n",
    "print(metrics_df) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00f980b4",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baea55a5",
   "metadata": {},
   "source": [
    "## `Baseline` CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "136d3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    LR = 0.01 # learning rate parameter for Adam\n",
    "    \n",
    "    # build network\n",
    "    inp = layers.Input(shape=(224, 224, 3))\n",
    "    cnn = layers.Conv2D(8, (3, 3), activation='relu')(inp)\n",
    "    cnn2 = layers.MaxPooling2D((2, 2))(cnn)\n",
    "    cnn3 = layers.Conv2D(16, (3, 3), activation='relu')(cnn2)\n",
    "    cnn4 = layers.MaxPooling2D((2, 2))(cnn3)\n",
    "    \n",
    "    flatten = layers.Flatten()(cnn4)\n",
    "    dense1 = layers.Dense(16, activation='relu')(flatten)\n",
    "    out = layers.Dense(6, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=LR), metrics=[\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.AUC(name='pr_auc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        'accuracy'\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd420e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 46656)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                746512    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 748,006\n",
      "Trainable params: 748,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "model = build_model()\n",
    "model.class_indices_ = train_gen.class_indices\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25d8e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16829/304877126.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(generator = train_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2802 - auc: 0.7664 - pr_auc: 0.2239 - precision: 0.1212 - recall: 1.9831e-04 - accuracy: 0.6878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 05:42:12.820814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-26 05:42:12.904784: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.904814: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.904834: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.904844: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.905981: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.906018: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.906032: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.906044: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.906829: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.906852: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.906865: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.906873: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.907959: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.907971: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.907982: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.907999: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.908952: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.908961: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.908972: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.908980: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.909540: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.909559: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 05:42:12.909570: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48004 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-26 05:42:12.909577: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45099 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: loss improved from inf to 0.28018, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 213s 201ms/step - loss: 0.2802 - auc: 0.7664 - pr_auc: 0.2239 - precision: 0.1212 - recall: 1.9831e-04 - accuracy: 0.6878 - val_loss: 0.2702 - val_auc: 0.7880 - val_pr_auc: 0.2591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.6993 - lr: 0.0100\n",
      "Epoch 2/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2717 - auc: 0.7838 - pr_auc: 0.2561 - precision: 0.4605 - recall: 8.6765e-04 - accuracy: 0.6883\n",
      "Epoch 2: loss improved from 0.28018 to 0.27174, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 219s 207ms/step - loss: 0.2717 - auc: 0.7838 - pr_auc: 0.2561 - precision: 0.4605 - recall: 8.6765e-04 - accuracy: 0.6883 - val_loss: 0.2729 - val_auc: 0.7875 - val_pr_auc: 0.2614 - val_precision: 0.2857 - val_recall: 1.9812e-04 - val_accuracy: 0.6941 - lr: 0.0100\n",
      "Epoch 3/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2716 - auc: 0.7842 - pr_auc: 0.2594 - precision: 0.6333 - recall: 0.0024 - accuracy: 0.6886\n",
      "Epoch 3: loss improved from 0.27174 to 0.27163, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 227s 215ms/step - loss: 0.2716 - auc: 0.7842 - pr_auc: 0.2594 - precision: 0.6333 - recall: 0.0024 - accuracy: 0.6886 - val_loss: 0.2712 - val_auc: 0.7880 - val_pr_auc: 0.2584 - val_precision: 0.1765 - val_recall: 2.9732e-04 - val_accuracy: 0.6942 - lr: 0.0100\n",
      "Epoch 4/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2709 - auc: 0.7853 - pr_auc: 0.2634 - precision: 0.7466 - recall: 0.0041 - accuracy: 0.6881\n",
      "Epoch 4: loss improved from 0.27163 to 0.27092, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 220s 208ms/step - loss: 0.2709 - auc: 0.7853 - pr_auc: 0.2634 - precision: 0.7466 - recall: 0.0041 - accuracy: 0.6881 - val_loss: 0.2722 - val_auc: 0.7878 - val_pr_auc: 0.2587 - val_precision: 0.1875 - val_recall: 2.9724e-04 - val_accuracy: 0.6947 - lr: 0.0100\n",
      "Epoch 5/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2704 - auc: 0.7866 - pr_auc: 0.2667 - precision: 0.8161 - recall: 0.0060 - accuracy: 0.6893\n",
      "Epoch 5: loss improved from 0.27092 to 0.27043, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 221s 209ms/step - loss: 0.2704 - auc: 0.7866 - pr_auc: 0.2667 - precision: 0.8161 - recall: 0.0060 - accuracy: 0.6893 - val_loss: 0.2745 - val_auc: 0.7875 - val_pr_auc: 0.2604 - val_precision: 0.2308 - val_recall: 5.9465e-04 - val_accuracy: 0.6937 - lr: 0.0100\n",
      "Epoch 6/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2695 - auc: 0.7869 - pr_auc: 0.2689 - precision: 0.8879 - recall: 0.0073 - accuracy: 0.6891\n",
      "Epoch 6: loss improved from 0.27043 to 0.26953, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 239s 225ms/step - loss: 0.2695 - auc: 0.7869 - pr_auc: 0.2689 - precision: 0.8879 - recall: 0.0073 - accuracy: 0.6891 - val_loss: 0.2753 - val_auc: 0.7873 - val_pr_auc: 0.2606 - val_precision: 0.2727 - val_recall: 5.9418e-04 - val_accuracy: 0.6942 - lr: 1.0000e-03\n",
      "Epoch 7/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2692 - auc: 0.7877 - pr_auc: 0.2716 - precision: 0.9208 - recall: 0.0078 - accuracy: 0.6892\n",
      "Epoch 7: loss improved from 0.26953 to 0.26917, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 246s 232ms/step - loss: 0.2692 - auc: 0.7877 - pr_auc: 0.2716 - precision: 0.9208 - recall: 0.0078 - accuracy: 0.6892 - val_loss: 0.2764 - val_auc: 0.7875 - val_pr_auc: 0.2616 - val_precision: 0.2667 - val_recall: 7.9271e-04 - val_accuracy: 0.6950 - lr: 1.0000e-03\n",
      "Epoch 8/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2689 - auc: 0.7877 - pr_auc: 0.2727 - precision: 0.9457 - recall: 0.0082 - accuracy: 0.6891\n",
      "Epoch 8: loss improved from 0.26917 to 0.26893, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 260s 246ms/step - loss: 0.2689 - auc: 0.7877 - pr_auc: 0.2727 - precision: 0.9457 - recall: 0.0082 - accuracy: 0.6891 - val_loss: 0.2785 - val_auc: 0.7870 - val_pr_auc: 0.2610 - val_precision: 0.2500 - val_recall: 7.9247e-04 - val_accuracy: 0.6947 - lr: 1.0000e-03\n",
      "Epoch 9/10\n",
      "1058/1058 [==============================] - ETA: 0s - loss: 0.2688 - auc: 0.7877 - pr_auc: 0.2742 - precision: 0.9598 - recall: 0.0089 - accuracy: 0.6894\n",
      "Epoch 9: loss improved from 0.26893 to 0.26876, saving model to DV_Basemodel_v0.hdf5\n",
      "1058/1058 [==============================] - 254s 240ms/step - loss: 0.2688 - auc: 0.7877 - pr_auc: 0.2742 - precision: 0.9598 - recall: 0.0089 - accuracy: 0.6894 - val_loss: 0.2790 - val_auc: 0.7872 - val_pr_auc: 0.2612 - val_precision: 0.2222 - val_recall: 7.9279e-04 - val_accuracy: 0.6948 - lr: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "# Remember to change the run number so that we do not overwrite the\n",
    "# saved model\n",
    "\n",
    "RUN_NUMBER = 0\n",
    "MODEL_NAME = f'DV_Basemodel_v{RUN_NUMBER}.hdf5'\n",
    "\n",
    "cb = [callbacks.EarlyStopping(patience=8),\n",
    "      callbacks.ReduceLROnPlateau(patience=4),\n",
    "      callbacks.ModelCheckpoint(MODEL_NAME,\n",
    "                                monitor='loss',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True)]\n",
    "\n",
    "# check the first epochs, if the metrics go to zero\n",
    "# restart the run with slightly different hyperparameter\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit_generator(generator = train_gen,\n",
    "                              steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = STEP_SIZE_VALID,\n",
    "                              epochs = epochs,\n",
    "                              callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c850c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"DVmodelBaseCNN.pkl\"\n",
    "with open(model_name, 'wb') as archivo:\n",
    "    pickle.dump(MODEL_NAME, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a232869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_history(history)\n",
    "plot_history(history, path=\"standard.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87d08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03cf8f6d",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "531ac866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAFOs',\n",
       " 'Landfills',\n",
       " 'Mines',\n",
       " 'ProcessingPlants',\n",
       " 'RefineriesAndTerminals',\n",
       " 'WWTreatment']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names = list(test_gen.class_indices.keys())\n",
    "cat_names.remove('Negative')\n",
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbce90b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'methane_224_data/smallsize224/test_images/38.787_-121.379/naip.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb Celda 50\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m test_gen\u001b[39m.\u001b[39;49mnext()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_proba \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;32m/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb Celda 50\u001b[0m in \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     X_, y_ \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mnext()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     y_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdelete(y_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_indices[\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/code/dvictoria2/methane_source/DV_Baseline_corr_metrics.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X_, y_\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/preprocessing/image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[1;32m    166\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/preprocessing/image.py:370\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m filepaths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepaths\n\u001b[1;32m    369\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(index_array):\n\u001b[0;32m--> 370\u001b[0m     img \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39;49mload_img(\n\u001b[1;32m    371\u001b[0m         filepaths[j],\n\u001b[1;32m    372\u001b[0m         color_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolor_mode,\n\u001b[1;32m    373\u001b[0m         target_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_size,\n\u001b[1;32m    374\u001b[0m         interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[1;32m    375\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeep_aspect_ratio,\n\u001b[1;32m    376\u001b[0m     )\n\u001b[1;32m    377\u001b[0m     x \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39mimg_to_array(img, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n\u001b[1;32m    378\u001b[0m     \u001b[39m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[39m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, pathlib\u001b[39m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path\u001b[39m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(io\u001b[39m.\u001b[39mBytesIO(f\u001b[39m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'methane_224_data/smallsize224/test_images/38.787_-121.379/naip.png'"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_gen.next()\n",
    "y_pred_proba = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use that if you want to save the arrays\n",
    "#np.save(f'y_pred_proba_{RUN_NUMBER}.npy', y_pred_proba)\n",
    "#np.save(f'y_test_{RUN_NUMBER}.npy', y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd5cf82b",
   "metadata": {},
   "source": [
    "## Plot the distribution of a few predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d86905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_pred_proba[:20].T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test[:20].T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a sample image from the test set\n",
    "abc = X_test[0,:,:,:].reshape(224, 224, 3).astype(np.uint8)\n",
    "plt.imshow(abc)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "515fad53",
   "metadata": {},
   "source": [
    "## Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5dcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate metrics\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "pr_auc = tf.keras.metrics.AUC(name='pr_auc', curve='PR')\n",
    "accuracy = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize predictions\n",
    "y_pred = (y_pred_proba> 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ca891",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_cat = {}\n",
    "recall_cat = {}\n",
    "auc_cat = {}\n",
    "pr_auc_cat = {}\n",
    "accuracy_cat = {}\n",
    "overall_cat = {}\n",
    "\n",
    "def calc_metric(y_test, y_pred, m_dict, m_fun, idx, name):\n",
    "    m_dict[name] = m_fun(y_test[:][:,idx].reshape(TEST_BATCH_SIZE,1), y_pred[:][:,idx].reshape(TEST_BATCH_SIZE,1)).numpy()\n",
    "\n",
    "dicts = [prec_cat, recall_cat, auc_cat, pr_auc_cat, accuracy_cat]\n",
    "funcs = [precision, recall, auc, pr_auc, accuracy]\n",
    "\n",
    "for idx, name in enumerate(cat_names):\n",
    "    for m_dict, m_fun in zip(dicts, funcs):\n",
    "        calc_metric(y_test, y_pred, m_dict, m_fun, idx, name)\n",
    "    overall_cat[name] = np.mean([d[name] for d in dicts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d46d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Category': cat_names,\n",
    "    'Precision': list(prec_cat.values()),\n",
    "    'Recall': list(recall_cat.values()),\n",
    "    'AUC': list(auc_cat.values()),\n",
    "    'PR AUC': list(pr_auc_cat.values()),\n",
    "    'Accuracy': list(accuracy_cat.values()),\n",
    "    'Overall': list(overall_cat.values())\n",
    "})\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7806f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
